{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "866ed254",
      "metadata": {
        "id": "866ed254"
      },
      "source": [
        "# Approximate Nearest Neighbors:\n",
        "\n",
        "# Image Recommendation System via Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f494560c",
      "metadata": {
        "id": "f494560c"
      },
      "source": [
        "## About the Dataset\n",
        "Behance is a community art website where users showcase and discover creative work. Each user is able to “appreciate” (equivalent to a “like” on Instagram or a “react” on Facebook) an image, indicating that they like the image. It is in the website’s best interests to show users pictures that they would like, to keep them engaged for longer. For this question, given a set of pictures that a user has already appreciated, you have to show them a new picture that they would like based on what similar users appreciated.\n",
        "\n",
        "\n",
        "<br><br>\n",
        "**The dataset has information of 1 million appreciates of 63,497 users on 178,788 items. The file Behance appreciate 1M has a triplet in each line in the form of (user id, item id, unix timestamp).**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a52fe5",
      "metadata": {
        "id": "68a52fe5"
      },
      "source": [
        "**Output file format:**\n",
        "Populate the output file with images that the user has not seen of the k most\n",
        "similar users, in descending order of their similarity. Each line in the output\n",
        "file should be a duplet in the form of (item id, user id), where the user id is the\n",
        "id of the kth similar user. The order of the images corresponding to the same\n",
        "similar user would not matter. The output file would look something like this:\n",
        "```\n",
        "item_id_1_of_1st_similar_user 1st_most_similar_user_id\n",
        "item_id_2_of_1st_similar_user 1st_most_similar_user_id\n",
        "item_id_3_of_1st_similar_user 1st_most_similar_user_id\n",
        "...\n",
        "item_id_1_of_2nd_similar_user 2nd_most_similar_user_id\n",
        "item_id_2_of_2nd_similar_user 2nd_most_similar_user_id\n",
        "item_id_3_of_2nd_similar_user 2nd_most_similar_user_id\n",
        "...\n",
        "item_id_1_of_kth_similar_user kth_most_similar_user_id\n",
        "item_id_2_of_kth_similar_user kth_most_similar_user_id\n",
        "item_id_3_of_kth_similar_user kth_most_similar_user_id\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d46fd2",
      "metadata": {
        "id": "26d46fd2"
      },
      "source": [
        "The dataset was extracted using Behance’s API as a part of the paper\n",
        "“Vista: A visually, socially, and temporally-aware model for artistic\n",
        "recommendation, RecSys, 2016”.Check out this [Google Drive folder](https://drive.google.com/drive/folders/0B9Ck8jw-TZUEc3NlMjVXdDlPU1k?resourcekey=0-6_8ykn0o4fLc5fuTEm91xA) for\n",
        "more information about the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912088cf",
      "metadata": {
        "id": "912088cf"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Y13duQFWyf",
        "outputId": "680cca31-4bfb-447c-b57a-00a112855b19"
      },
      "id": "W5Y13duQFWyf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (5.0.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13e9cbe3",
      "metadata": {
        "id": "13e9cbe3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from scipy import spatial\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9c4cd1",
      "metadata": {
        "id": "0c9c4cd1"
      },
      "outputs": [],
      "source": [
        "# Config Generation Sample Code.\n",
        "# ⚠️ Only for experimentation on your side.\n",
        "# ⚠️ Should be commented during submission.\n",
        "\n",
        "# df = pd.DataFrame(data=[{'id':276633,\n",
        "#                   'k':5,\n",
        "#                   'dataset_file':'./Behance_appreciate_1M',\n",
        "#                   'output_file':'./output.txt'}])\n",
        "# df.to_csv('config.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6bc1ff",
      "metadata": {
        "id": "cb6bc1ff"
      },
      "outputs": [],
      "source": [
        "config = pd.read_csv('config.csv').iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef721d6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef721d6b",
        "outputId": "abfab106-8fc2-4e6b-c626-7f135f5f1cec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                            0\n",
              "id                               276633\n",
              "k                                     5\n",
              "dataset_file    ./Behance_appreciate_1M\n",
              "output_file                ./output.txt\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4966a889",
      "metadata": {
        "id": "4966a889"
      },
      "outputs": [],
      "source": [
        "user = config['id']\n",
        "k_value = config['k']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e50dee",
      "metadata": {
        "id": "e8e50dee"
      },
      "source": [
        "### Read the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd74173b",
      "metadata": {
        "id": "cd74173b"
      },
      "outputs": [],
      "source": [
        "with open(config['dataset_file'], 'r') as inFile:\n",
        "    appreciate_data = inFile.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8542cda",
      "metadata": {
        "id": "e8542cda"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "# appreciate_data = appreciate_data[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e09e9961",
      "metadata": {
        "id": "e09e9961"
      },
      "source": [
        "### Initialize a dictionary to store the item_ids that a user likes\n",
        "\n",
        "### Go through each line of the input file and construct the user_likes dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ff4a80d",
      "metadata": {
        "id": "8ff4a80d"
      },
      "outputs": [],
      "source": [
        "user_likes = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b55dc0b",
      "metadata": {
        "id": "5b55dc0b"
      },
      "outputs": [],
      "source": [
        "for line in appreciate_data:\n",
        "    line = line.strip()\n",
        "    \n",
        "    user_id = int(line.split()[0])\n",
        "    item_id = int(line.split()[1])\n",
        "\n",
        "    if user_id not in user_likes:\n",
        "        user_likes[user_id] = list()\n",
        "    \n",
        "    user_likes[user_id].append(item_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# user_likes"
      ],
      "metadata": {
        "id": "rNtZl2tZB5rd"
      },
      "id": "rNtZl2tZB5rd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cd017880",
      "metadata": {
        "id": "cd017880"
      },
      "source": [
        "### Use your choice of Approximate Nearest Neigbor after Collaborative Filtering to find nearest neighbors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_item_id = set()\n",
        "for keys in user_likes:\n",
        "  temp = user_likes[keys]\n",
        "  for value in temp:\n",
        "    unique_item_id.add(value)\n",
        "unique_user_id = set()\n",
        "for keys in user_likes:\n",
        "  unique_user_id.add(keys)"
      ],
      "metadata": {
        "id": "z5o7YpoTB8YM"
      },
      "id": "z5o7YpoTB8YM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_map = {}\n",
        "item_map = {}\n",
        "for i,user in enumerate(list(unique_user_id)):\n",
        "  user_map[user] = i\n",
        "for i,item in enumerate(list(unique_item_id)):\n",
        "  item_map[item] = i\n",
        "# print(user_map)\n",
        "# print(item_map)"
      ],
      "metadata": {
        "id": "ZPavPUQcB_Zh"
      },
      "id": "ZPavPUQcB_Zh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = [[0 for i in range(len(unique_item_id))] for j in range(len(unique_user_id))]\n",
        "# print(len(matrix))\n",
        "for i in user_likes: \n",
        "  temp = user_likes[i]\n",
        "  for j in temp:\n",
        "    matrix[user_map[i]][item_map[j]] += 1"
      ],
      "metadata": {
        "id": "s3pgfkV3CBxy"
      },
      "id": "s3pgfkV3CBxy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd = TruncatedSVD(n_components=500)\n",
        "new_matrix = svd.fit_transform(matrix)\n",
        "# print(len(new_matrix))\n",
        "# print(len(new_matrix[0]))"
      ],
      "metadata": {
        "id": "G4TAk3z6CD0v"
      },
      "id": "G4TAk3z6CD0v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee1d377",
      "metadata": {
        "id": "5ee1d377"
      },
      "outputs": [],
      "source": [
        "new_matrix = np.asarray(new_matrix, np.float32)\n",
        "# print(type(new_matrix))\n",
        "# print(new_matrix.shape)\n",
        "k = 5\n",
        "d = 359\n",
        "xq = new_matrix\n",
        "index = faiss.index_factory(d, \"Flat\")\n",
        "index.train(new_matrix)\n",
        "index.add(new_matrix)\n",
        "distances, neighbors = index.search(xq, k)\n",
        "# print(distances)\n",
        "# print(neighbors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b6f24d6",
      "metadata": {
        "id": "0b6f24d6"
      },
      "source": [
        "### Answer the following questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012f72f8",
      "metadata": {
        "id": "012f72f8"
      },
      "source": [
        "#### Q1. **Explain how your choice of library works**\n",
        "\n",
        "The library I have used is `faiss`. <br />\n",
        "Given a set of vectors x_i in some dimension d, Faiss creates a data structure in RAM. Once the structure is built, it efficiently performs the function of finding the minimum Euclidean distance between any two vectors given any new vector x in dimension d, that is,\n",
        "it efficiently performs the following function:\n",
        "i = argmin_i ||x-x_i|| <br/>\n",
        "Computing the argmin is the search operation on the index where the index is the data structure created by Faiss.\n",
        "The data structure in Faiss is an object which has an add method that adds x_i vectors (where x_i's are fixed). <br/>\n",
        "faiss can search several vectors at the same time and stores the index on disk instead of in RAM. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0ac14b",
      "metadata": {
        "id": "3b0ac14b"
      },
      "source": [
        "#### Q2. **Compare your choice of library with vanilla KNN.**\n",
        "***Hint: Include Time Complexity, and explain the tradeoff with recall***\n",
        "\n",
        "The time complexity for KNN is O(1) for training and O(n) for testing thus it depends on the number of test examples. <br />\n",
        "The time complexity of KNN is `O(n*m)` for the brute-force neighbour search where n is the training examples and m is the number of dimensions in the training set whereas the underlying algorithmic novelty behind faiss takes an `O(nlog2n)` sort and parallelizes it to something that takes `O(log2n)` serial time. <br />\n",
        "The problem in KNN arises when classes overlap and when sample size is unevenly distributed between categories thus requiring methods that increase classification rate in terms of recall measure."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "400d7827",
      "metadata": {
        "id": "400d7827"
      },
      "source": [
        "#### Q3. **Compare your choice of library with implementation of ScaNN, faiss and annoy.**\n",
        "***Hint: Include Time Complexity, and explain the tradeoff with recall***\n",
        "\n",
        "faiss returns not just the nearest neighbour but also the k-th nearest neighbors. It can trade precision for speed. For instance, by giving an incorrect answer 10% of the time using a method that uses 10x less memory. \n",
        "The underlying algorithmic novelty behind faiss takes an O(nlog2n) sort and parallelizes it to something that takes O(log2n) serial time. <br />\n",
        "On the other hand, Annoy requires two main parameters namely number of tress `n_trees` and the number of nodes to inspect during searching `search_k`. <br />\n",
        "`n_trees` affects the build time and the index size whereas `search_k` affects the search performance. <br />\n",
        "Annoy comes with huge speed but does not guarantee to find the nearest one, it approximates. It reduces the time complexity to `O(logn)`<br />\n",
        "ScaNN includes search space pruning and quantization for Maximum Inner Product Search and also supports other distance functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "142440b0",
      "metadata": {
        "id": "142440b0"
      },
      "source": [
        "### Open the output file to write all the lines to the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977b08f9",
      "metadata": {
        "id": "977b08f9"
      },
      "outputs": [],
      "source": [
        "outFile = open(config['output_file'], 'w')\n",
        "\n",
        "inv_user = {v: k for k, v in user_map.items()}\n",
        "\n",
        "for i,neighbor in enumerate(neighbors):\n",
        "  for j,users in enumerate(neighbor):\n",
        "    if j == 0:\n",
        "      continue\n",
        "    for item_id in user_likes[inv_user[users]]:\n",
        "      if item_id not in user_likes[inv_user[i]]:\n",
        "        outFile.write(str(item_id) + ' ' + str(inv_user[users]) + '\\n')\n",
        "\n",
        "outFile.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}